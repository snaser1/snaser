# Visual Acuity 

```{problem_description}
Suppose we are interested in the hypothesis that children playing outside leads them to have better eyesight.

Consider the following population of ten children whose visual acuity we can measure. 

- Visual acuity is the decimal version of the fraction given as output in standard eye exams. 
- Someone with 20/20 vision has acuity 1.0, while someone with 20/40 vision has acuity 0.5. 
- Numbers greater than 1.0 are possible for people with better than “normal” visual acuity.
```

```{r make visual data}
library(data.table)
d <- data.table(
  child = 1:10, 
  y_0 = c(1.2, 0.1, 0.5, 0.8, 1.5, 2.0, 1.3, 0.7, 1.1, 1.4), 
  y_1 = c(1.2, 0.7, 0.5, 0.8, 0.6, 2.0, 1.3, 0.7, 1.1, 1.4)
)
```

```{problem_description}
In this table: 

- `y_1` means the measured *visual acuity* if the child were to play outside at least 10 hours per week from ages 3 to 6  
- `y_0` means the measured *visual acuity* if the child were to play outside fewer than 10 hours per week from age 3 to age 6; 
- Both of these potential outcomes *at the child level* would be measured at the same time, when the child is 6. 
```

## Treatment effect
Compute the individual treatment effect for each of the ten children.  

```{r, include = TRUE}
# Use this code chunk to show your code work
d[, tau := y_1 - y_0]

d
```  

**Answer:** ...

## Story time
Tell a "story" that could explain this distribution of treatment effects. In particular, discuss what might cause some children to have different treatment effects than others.  

```{problem_description}
# Use this code chunk to show your code work (if needed)

In a small town, there lived ten children, each with their unique lifestyle and genetic background, presenting an intriguing case study on the effects of outdoor play on visual acuity.

Majority Unaffected (Children 1, 3, 4, 6, 7, 8, 9, 10): These children, despite varying hours of outdoor play, showed no change in their visual acuity. This could be attributed to several factors:

Sufficient Prior Outdoor Activity: They might have already been engaging in enough outdoor activities, making the additional prescribed hours less impactful.
Genetic Factors: Their visual acuity might be more strongly influenced by genetics than environmental factors like outdoor play.
Adaptation: They could have quickly adapted to the increased outdoor play without significant changes in their eyesight.
Significant Improvement (Child 2): This child's visual acuity improved remarkably from 0.1 to 0.7. Possible reasons include:

Lack of Prior Exposure: Initially, this child might have had limited exposure to outdoor activities. The increased playtime could have introduced beneficial stimuli for eye development, such as distance focusing and varied visual environments.
Personal Health Changes: The child might have undergone developmental changes during the intervention period that positively impacted their eyesight.
A Unique Decrease (Child 5): Contrasting with others, Child 5 experienced a reduction in visual acuity (from 1.5 to 0.6). This unusual case could be due to:

Overexposure to Sunlight: Excessive outdoor play might have led to overexposure to sunlight, potentially causing strain or temporary vision impairment.
Individual Sensitivity: This child might have a unique sensitivity to environmental changes or specific outdoor conditions that negatively affected their eyesight.
In this small town, each child's response to the intervention of increased outdoor playtime highlights the complex interplay of environmental factors, personal health, lifestyle, and genetic predispositions in influencing visual acuity. The varied outcomes underscore the importance of considering individual differences in response to environmental interventions.
```  

**Answer:** ...

## True ATE
For this population, what is the true average treatment effect (ATE) of playing outside.    

```{r, include = TRUE}
# Use this code chunk to show your code work
# Compute the individual treatment effect for each child
d[, tau := y_1 - y_0]

# Calculate the true Average Treatment Effect (ATE)
ATE <- mean(d$tau)

ATE

```

**Answer:** ...

## Even-Odd split
Suppose we are able to do an experiment in which we can control the amount of time these children play outside for three years. We happen to randomly assign the odd-numbered children to treatment and the even-numbered children to control. What is the estimate of the ATE you would reach under this assignment? (Please describe your work.)  

```{r, include = TRUE}

# Treatment group: Odd-numbered children
treatment_group <- d[child %% 2 != 0, mean(y_1)]

# Control group: Even-numbered children
control_group <- d[child %% 2 == 0, mean(y_0)]

# Compute the estimated ATE
estimated_ATE <- treatment_group - control_group

# Output the estimated ATE
estimated_ATE

```

**Answer:** ...

## Biased or Unbiased?
How different is the estimate from the truth? In your own words, why is there a difference? Does this mean that the estimator is a biased or an unbiased estimator? Does this mean that the estimate is biased or unbiased? 

```{}
# Use this code chunk to show your code work

The estimated ATE from the experiment is -0.06, while the true ATE calculated from the data is -0.03. The difference is 0.03.

The difference arises because the method of assigning treatment (odd-numbered children to treatment and even-numbered to control) may not ensure a truly random and balanced assignment. This specific method of assignment could create systematic differences between the treatment and control groups unrelated to the treatment effect, leading to a deviation in the estimated ATE from the true ATE.

In general, the difference in means (used here as an estimator) is an unbiased estimator for ATE when the treatment is assigned randomly. However, in this specific instance, the way the treatment was assigned (based on odd/even numbering) may introduce bias, making this particular estimate biased. This does not imply the estimator is inherently biased, but rather that the estimate in this specific context is biased due to the non-random nature of the assignment method.


```

**Answer:** ...

## How many splits are possible? 
We just considered one way (odd-even) an experiment might split the children. How many different ways (every possible way) are there to split the children into a treatment versus a control group (assuming at least one person is always in the treatment group and at least one person is always in the control group)?  

```{}
# Use this code chunk to show your code work
To determine the number of possible ways to split the children into a treatment and a control group, given that at least one person must always be in each group, we can use the concept of power sets with some modifications.

There are 10 children in total. For each child, there are two possibilities: either they are in the treatment group or in the control group. This creates \(2^{10}\) (or 1024) total combinations if we consider all possible groupings, including the ones where all children are in one group and none in the other.

However, since we must have at least one child in each group, we need to exclude these two scenarios (all in treatment and all in control). Therefore, the total number of valid splits is \(2^{10} - 2\) which equals 1024 - 2 = 1022.

So, there are 1022 different ways to split the children into a treatment versus a control group under these conditions.
```

**Answer:** ...

## Thinking about your assignment strategy
Given there are as many ways to assign as you answered in the last sub-question, can you provide a rationale for why you might prefer one assignment strategy over another? 

For concreteness, suppose that either (a) you can have a treatment assignment where one and only one of the kids is randomly assigned to treatment; or (b) you can have a treatment assignment where exactly five of the kids are randomly assigned to treatment. 

As a small hint, you might note that $\left\{\left[\displaystyle\sum_{i=1}^{n}Y_{i}(1)|d_{i}=1\right] - \left[\displaystyle\sum_{j=1}^{n}Y_{j}(0)|d_{j} = 0 \right]\right\} \equiv ATE$ is an estimator and there are some properties of estimators that we care about.  

To make the question tractable, suppose that if you were to increase the size of the population procedure (a) would keep a single kid in treatment, while procedure (b) would keep 50% of the sample in treatment and 50% of the sample in control.

**Answer:** ...

```{}
Tthere are several key factors to consider, primarily related to the properties of the estimator used for the Average Treatment Effect (ATE).

Variance of the Estimator: In procedure (a), where only one child is in the treatment group, the variance of the estimator will be high. This is because the treatment effect is being estimated based on a single observation, which may not be representative of the population. Small sample sizes in experimental groups lead to high variability in the estimated treatment effects.
In contrast, procedure (b), with a 50-50 split, provides a larger sample size for both treatment and control groups, thereby reducing the variance of the estimator. A larger sample size tends to give a more reliable and stable estimate of the ATE.

Precision and Reliability: With only one child in the treatment group, the estimate of ATE may not be precise or reliable. The outcome for this one child could be an outlier or influenced by factors not representative of the general population.
A 50-50 split allows for a more balanced comparison and increases the likelihood that the treatment and control groups are similar in terms of other characteristics, leading to a more precise and reliable estimate of ATE.

Representativeness: Having a larger proportion of the population in each group (as in procedure b) ensures that the sample is more representative of the population. This is crucial for the generalizability of the experimental results.

Given these considerations, procedure (b) – having exactly half of the children in the treatment group – is generally preferred over procedure (a). It offers lower variance, greater precision and reliability, better representativeness, and higher statistical power.
```

## Compute the MSE of these two designs
Because you have the entire population of kids, their entire scheduled of potential outcomes, and two proposed sampling procedures: conduct a simulation study. First, calculate all of the possible treatment effects that you might observe under each design. Then, compute the mean-squared error of each design. Which design -- the one where you have a single kid in treatment, or the one where you have five kids in treatment -- produces a lower MSE? (Hint the `combn` function might help you with your subsetting.) 

```{r, include = TRUE}
# Use this code chunk to show your code work
y_0 = c(1.2, 0.1, 0.5, 0.8, 1.5, 2.0, 1.3, 0.7, 1.1, 1.4)
y_1 = c(1.2, 0.7, 0.5, 0.8, 0.6, 2.0, 1.3, 0.7, 1.1, 1.4)
true_ATE <- mean(y_1 - y_0)
calculate_MSE <- function(treatment_indices) {
  # Calculate observed treatment effects for each combination
  observed_treatment_effects <- sapply(treatment_indices, function(indices) {
    mean(y_1[indices]) - mean(y_0[-indices])
  })
  # Compute MSE
  mean((observed_treatment_effects - true_ATE)^2)
}

# Design a: Single kid in treatment
combinations_a <- combn(1:10, 1)
mse_a <- calculate_MSE(combinations_a)

# Design b: Five kids in treatment
combinations_b <- combn(1:10, 5)
mse_b <- calculate_MSE(combinations_b)

# Compare MSEs
mse_a
mse_b

```

**Answer:** ...

## Observational study 
Suppose that we decide it is too hard to control the behavior of the children, so we do an observational study instead. Children 1-5 choose to play an average of more than 10 hours per week from age 3 to age 6, while Children 6-10 play less than 10 hours per week. Compute the difference in means from the resulting observational data.  

```{r, include = TRUE}
# Use this code chunk to show your code work

```

**Answer:** ...

## Observational ATE 
Compare your answer in `Observational study` to the true ATE. In your own words what causes the difference? Does this mean that the estimator is a biased or an unbiased estimator? Does this mean that the estimate is biased or unbiased? 


**Answer:** ...
```{}
# Use this code chunk to show your code work (if needed)
In an observational study, the estimated Average Treatment Effect (ATE) may differ from the true ATE primarily due to selection bias, confounding variables, and the lack of randomization in treatment assignment. These factors can introduce systematic errors:

Selection Bias: If children who are more likely to play outside also have inherently better or worse visual acuity due to reasons not related to the treatment, this can skew the estimated ATE.

Confounding Variables: Factors that influence both the likelihood of receiving the treatment and the outcome itself, if not accounted for, can lead to a biased estimate.

Lack of Randomization: Without random assignment to treatment and control groups, it's challenging to isolate the effect of the treatment from other factors.

As a result, the estimator used in an observational study can be biased if these issues consistently lead to overestimation or underestimation of the true ATE. The specific estimate obtained from such a study is likely biased due to the non-random nature of the treatment assignment and the presence of confounding factors.
```
